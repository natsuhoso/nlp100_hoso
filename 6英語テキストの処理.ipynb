{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50. 文区切り\n",
    "(. or ; or : or ? or !) → 空白文字 → 英大文字というパターンを文の区切りと見なし，入力された文書を1行1文の形式で出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def search(line, file):\n",
    "    x = re.search('^(?P<sente>.*?)(?P<mark>[.;:?!])( (?P<newline>[A-Z].*))?$|^(?P<title>.*)$', line)\n",
    "    if x:\n",
    "        sente = x.group('sente')\n",
    "        mark = x.group('mark')\n",
    "        newline = x.group('newline')\n",
    "        title = x.group('title')\n",
    "        if mark:\n",
    "            file.write(sente + mark + '\\n')\n",
    "        elif title:\n",
    "            file.write(title + '\\n')\n",
    "        if newline:\n",
    "            search(newline, file)\n",
    "    #else:\n",
    "        #print(line)\n",
    "    \n",
    "with open('data/file50', 'w'):\n",
    "    pass\n",
    "with open('data/file50', 'a') as a:\n",
    "    for line in open('data/nlp.txt'):\n",
    "        search(line, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 51. 単語の切り出し\n",
    "空白を単語の区切りとみなし，50の出力を入力として受け取り，1行1単語の形式で出力せよ．ただし，文の終端では空行を出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(line, file):\n",
    "    x = re.search('(?P<word>[^ ]*)( (?P<newline>.*))?', line)\n",
    "    if x:\n",
    "        word = x.group('word').strip('.,;:?!()\\\"')\n",
    "        newline = x.group('newline')\n",
    "        file.write(word + '\\n')\n",
    "        if newline:\n",
    "            search(newline, file)\n",
    "        else:\n",
    "            file.write('\\n')\n",
    "\n",
    "with open('data/file51', 'w'):\n",
    "    pass\n",
    "with open('data/file51', 'a') as a:\n",
    "    for line in open('data/file50'):\n",
    "        search(line, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 52. ステミング\n",
    "51の出力を入力として受け取り，Porterのステミングアルゴリズムを適用し，単語と語幹をタブ区切り形式で出力せよ． Pythonでは，Porterのステミングアルゴリズムの実装としてstemmingモジュールを利用するとよい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stemming.porter2 import stem\n",
    "\n",
    "with open('data/file52', 'w'):\n",
    "    pass\n",
    "with open('data/file52', 'a') as a:\n",
    "    for line in open('data/file51'):\n",
    "        line = line.strip('\\n')\n",
    "        a.write(line + '\\t' + stem(line) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 53. Tokenization\n",
    "Stanford Core NLPを用い，入力テキストの解析結果をXML形式で得よ．また，このXMLファイルを読み込み，入力テキストを1行1単語の形式で出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/file53', 'w'):\n",
    "    pass\n",
    "with open('data/file53', 'a') as a:\n",
    "    for line in  open('data/nlp.txt.xml'):\n",
    "        x = re.search('\\<word\\>(?P<word>.*?)\\<\\/word\\>', line)\n",
    "        if x:\n",
    "            a.write(x.group('word') + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 54. 品詞タグ付け\n",
    "Stanford Core NLPの解析結果XMLを読み込み，単語，レンマ，品詞をタブ区切り形式で出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/file54', 'w'):\n",
    "    pass\n",
    "with open('data/file54', 'a') as a:\n",
    "    for line in  open('data/nlp.txt.xml'):\n",
    "        x = re.search('\\<(?P<title>.*?)\\>(?P<info>.*?)\\<\\/(?P=title)\\>', line)\n",
    "        if x:\n",
    "            title = x.group('title')\n",
    "            info = x.group('info')\n",
    "            if title == 'word' or title == 'lemma':\n",
    "                a.write(info + '\\t')\n",
    "            elif title == 'POS':\n",
    "                a.write(info + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 55. 固有表現抽出\n",
    "入力文中の人名をすべて抜き出せ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/file55', 'w'):\n",
    "    pass\n",
    "with open('data/file55', 'a') as a:\n",
    "    flag = False\n",
    "    stack = []\n",
    "    for line in  open('data/nlp.txt.xml'):\n",
    "        x = re.search('\\<(?P<title>.*?)\\>(?P<info>.*?)\\<\\/(?P=title)\\>', line)\n",
    "        if x:\n",
    "            title = x.group('title')\n",
    "            info = x.group('info')\n",
    "            if title == 'word':\n",
    "                stack.append(info)\n",
    "            elif title == 'NER' and info != 'PERSON' and not flag:\n",
    "                stack = []\n",
    "            elif title == 'NER' and info != 'PERSON' and flag:\n",
    "                a.write('\\t'.join(stack[:-1]) + '\\n')\n",
    "                flag = False\n",
    "                stack = []\n",
    "            elif title == 'NER' and info == 'PERSON':\n",
    "                flag = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 56. 共参照解析\n",
    "Stanford Core NLPの共参照解析の結果に基づき，文中の参照表現（mention）を代表参照表現（representative mention）に置換せよ．ただし，置換するときは，「代表参照表現（参照表現）」のように，元の参照表現が分かるように配慮せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flag1 = False\n",
    "flag2 = False\n",
    "coreference = []\n",
    "mentions = []\n",
    "mention = {}\n",
    "for line in open('data/nlp.txt.xml'):\n",
    "    x = re.search('\\<coreference\\>', line)\n",
    "    if x and not flag1:\n",
    "        flag1 = True\n",
    "        continue\n",
    "    if x and flag1:\n",
    "        flag2 = True\n",
    "        continue\n",
    "    x = re.search('\\<\\/coreference\\>', line)\n",
    "    if x and not flag2:\n",
    "        flag1 = False\n",
    "        continue\n",
    "    if x and flag2:\n",
    "        flag2 = False\n",
    "        if len(mentions) > 1:\n",
    "            coreference.append(mentions)\n",
    "        mentions = []\n",
    "        continue\n",
    "    x = re.search('\\<(?P<title>.*?)\\>(?P<info>.*?)\\<\\/(?P=title)\\>', line)\n",
    "    if x and flag2:\n",
    "        title = x.group('title')\n",
    "        info = x.group('info')\n",
    "        if title == 'text' and mentions != [] and info == mentions[0]['text']:\n",
    "            continue\n",
    "        if title == 'sentence' or title == 'start' or title =='end':\n",
    "            mention.update({title: int(info) - 1})\n",
    "        elif title == 'text':\n",
    "            mention.update({title:info})\n",
    "            mentions.append(mention)\n",
    "            mention = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['many speech recognition systems',\n",
       "  'These systems',\n",
       "  'these systems',\n",
       "  'the systems'],\n",
       " ['machine learning algorithms',\n",
       "  'These algorithms',\n",
       "  'the earliest-used algorithms'],\n",
       " ['The machine-learning paradigm', 'The paradigm of machine learning'],\n",
       " ['you', 'your'],\n",
       " ['Such models', 'they'],\n",
       " ['My head', 'your head'],\n",
       " ['NLP', 'its'],\n",
       " ['hand-written rules --', 'the rules']]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[mention['text'] for mention in mentions] for mentions in coreference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "sentence= []\n",
    "for line in open('data/nlp.txt.xml'):\n",
    "    x = re.search('\\<word\\>(?P<word>.*?)\\<\\/word\\>', line)\n",
    "    if x:\n",
    "        sentence.append(x.group('word'))\n",
    "    elif re.search('\\<\\/sentence\\>', line):\n",
    "        sentences.append(sentence)\n",
    "        sentence = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "new_sentences = copy.deepcopy(sentences)\n",
    "for mentions in coreference:\n",
    "    for mention in mentions[1:]:\n",
    "        old_text = new_sentences[mention['sentence']][mention['start'] : mention['end']]\n",
    "        if len(old_text) == 1:\n",
    "            new_text = [mentions[0]['text'] + '(' + old_text[0] + ')']\n",
    "        else:\n",
    "            new_text = [mentions[0]['text'] + '(' + old_text[0]] + old_text[1:-1] + [old_text[-1] + ')']\n",
    "        new_sentences[mention['sentence']][mention['start'] : mention['end']] = new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['say', 'My head(you(your)', 'head)', 'hurts', '?', \"''\"]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sentences[11][34:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['say', 'your', 'head', 'hurts', '?', \"''\"]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[11][34:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/file56', 'w'):\n",
    "    pass\n",
    "with open('data/file56', 'a') as a:\n",
    "    for sentence in new_sentences:\n",
    "        a.write(' '.join(sentence) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
