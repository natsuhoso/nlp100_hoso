{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 70. データの入手・整形\n",
    "文に関する極性分析の正解データを用い，以下の要領で正解データ（sentiment.txt）を作成せよ．\n",
    "\n",
    "1. rt-polarity.posの各行の先頭に\"+1 \"という文字列を追加する（極性ラベル\"+1\"とスペースに続けて肯定的な文の内容が続く）\n",
    "2. rt-polarity.negの各行の先頭に\"-1 \"という文字列を追加する（極性ラベル\"-1\"とスペースに続けて否定的な文の内容が続く）\n",
    "3. 上述1と2の内容を結合（concatenate）し，行をランダムに並び替える\n",
    "\n",
    "sentiment.txtを作成したら，正例（肯定的な文）の数と負例（否定的な文）の数を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/sentiment.txt', 'w'):\n",
    "    pass\n",
    "with open('data/sentiment.txt', 'a')as a:\n",
    "    for pos, neg in zip(open('data/rt-polarity.pos'), open('data/rt-polarity.neg')):\n",
    "        a.write('+1 ' + pos)\n",
    "        a.write('-1 ' + neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sort data/sentiment.txt -R -o data/sentiment.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5331\n",
      "5331\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "neg = 0\n",
    "for line in open('data/sentiment.txt'):\n",
    "    if line[:2] == '+1':\n",
    "        pos = pos + 1\n",
    "    else:\n",
    "        neg = neg + 1\n",
    "print(pos)\n",
    "print(neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 71. ストップワード\n",
    "英語のストップワードのリスト（ストップリスト）を適当に作成せよ．さらに，引数に与えられた単語（文字列）がストップリストに含まれている場合は真，それ以外は偽を返す関数を実装せよ．さらに，その関数に対するテストを記述せよ．\n",
    "\n",
    "ストップワード：自然言語を処理するにあたって一般的であるなどの理由で処理対象外とする単語"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ググって拾ってきた\n",
    "stop_words=[\"(\", \")\", \"--\", \",\", \".\", \";\", \":\", \"\\'\", \"\\\"\", \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "dif = ord('a')-ord('A')\n",
    "stop_words = [chr(ord(i[0])-dif)+i[1:] for i in stop_words] + stop_words + [\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_sw(word):\n",
    "    if word in stop_words:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "for i in stop_words:\n",
    "    if in_sw(i) == False:\n",
    "        print('bloody hell!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 72. 素性抽出\n",
    "極性分析に有用そうな素性を各自で設計し，学習データから素性を抽出せよ．素性としては，レビューからストップワードを除去し，各単語をステミング処理したものが最低限のベースラインとなるであろう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stemming.porter2 import stem\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/file72', 'w'):\n",
    "    pass\n",
    "with open('data/file72', 'a')as a:\n",
    "    for line in open('data/sentiment.txt'):\n",
    "        a.write(' '.join([stem(word) for word in line[2:].split() if not in_sw(stem(word))]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115042\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for line in open('data/file72'):\n",
    "    words = words + line.split()\n",
    "count=Counter(words)\n",
    "print(len(words))\n",
    "del words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('film', 1800),\n",
       " ('movi', 1543),\n",
       " ('like', 805),\n",
       " ('make', 611),\n",
       " ('stori', 536),\n",
       " ('one', 763)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, count[i]) for i in count if count[i] > 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/features', 'w')as w:\n",
    "    w.write('\\n'.join([i for i in count if count[i] >= 10 and count[i] < 1000 ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2108"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i for i in count if count[i] >= 10 and count[i] < 1000 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 73. 学習\n",
    "72で抽出した素性を用いて，ロジスティック回帰モデルを学習せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = []\n",
    "for line in open('data/sentiment.txt'):\n",
    "    answer.append(int(line[:2])/2+0.5)\n",
    "answer = np.array(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2108\n"
     ]
    }
   ],
   "source": [
    "with open('data/features')as r:\n",
    "    features = r.read().split()\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.zeros((10662, 2109))\n",
    "matrix[:,0] = 1\n",
    "for line, i in zip(open('data/file72'), range(10662)):\n",
    "    for word in  line.split():\n",
    "        if word in features:\n",
    "            matrix[i][features.index(word) + 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4],\n",
       "       [3, 8]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1,2],[3,4]])*np.array([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "sigmoids = np.frompyfunc(sigmoid, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    mean = x.mean()\n",
    "    std = x.std()\n",
    "    return  (x - mean) / std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update():\n",
    "    v = v + 0.001 * np.dot(answer - sigmoids(matrix*v), matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.random.rand(2109)\n",
    "\n",
    "#matrix[:,1:]=standardize(matrix[:,1:])\n",
    "\n",
    "def standardize(x):\n",
    "    mean = x.mean()\n",
    "    std = x.std()\n",
    "    return  (x - mean) / std \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "sigmoids = np.frompyfunc(sigmoid, 1, 1)\n",
    "\n",
    "N = 100\n",
    "for _ in range(N):\n",
    "    v = v + 0.001 * np.dot(answer - sigmoids(np.dot(matrix,v)), matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 74. 予測\n",
    "73で学習したロジスティック回帰モデルを用い，与えられた文の極性ラベル（正例なら\"+1\"，負例なら\"-1\"）と，その予測確率を計算するプログラムを実装せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/file74', 'w'):\n",
    "    pass\n",
    "with open('data/file74', 'a')as a:\n",
    "    for i, j in zip(answer, sigmoids(np.dot(matrix,v))):\n",
    "        ans = 0\n",
    "        if j > 0.5:\n",
    "            ans = 1\n",
    "        a.write(str(int(i)) + str(ans) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok=[]\n",
    "for i, j in zip(answer, sigmoids(np.dot(matrix,v))):\n",
    "    ans = 0\n",
    "    if j > 0.5:\n",
    "        ans = 1\n",
    "    if int(i) == ans:\n",
    "        ok.append(True)\n",
    "    else:\n",
    "        ok.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.27443256424685"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i for i in ok if i == True])/len(ok)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75. 素性の重み\n",
    "73で学習したロジスティック回帰モデルの中で，重みの高い素性トップ10と，重みの低い素性トップ10を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst75 = sorted(list(enumerate(list(v))), key = lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['refresh',\n",
       " 'quiet',\n",
       " 'engross',\n",
       " 'beauti',\n",
       " 'unexpect',\n",
       " 'glorious',\n",
       " 'delight',\n",
       " 'cinema',\n",
       " 'witti',\n",
       " 'solid']"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[features[i[0]-1] for i in lst75][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neither',\n",
       " 'joke',\n",
       " 'tour',\n",
       " 'worst',\n",
       " 'video',\n",
       " 'fail',\n",
       " 'dull',\n",
       " 'lack',\n",
       " 'bore',\n",
       " 'bad']"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[features[i[0]-1] for i in lst75][-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 76. ラベル付け\n",
    "学習データに対してロジスティック回帰モデルを適用し，正解のラベル，予測されたラベル，予測確率をタブ区切り形式で出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/file76', 'w'):\n",
    "    pass\n",
    "with open('data/file76', 'a')as a:\n",
    "    for i, j in zip(answer, sigmoids(np.dot(matrix,v))):\n",
    "        if j > 0.5:\n",
    "            a.write(str(int(i)) + '\\t' + str(1) + '\\t' + str(j)+ '\\n')\n",
    "        else:\n",
    "            a.write(str(int(i)) + '\\t' + str(0) + '\\t' + str(1 - j) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 77. 正解率の計測\n",
    "76の出力を受け取り，予測の正解率，正例に関する適合率，再現率，F1スコアを求めるプログラムを作成せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "予測の正解率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.27443256424685\n"
     ]
    }
   ],
   "source": [
    "lst = []\n",
    "for line in open('data/file76'):\n",
    "    x = line.split()\n",
    "    if x[0] == x[1]:\n",
    "        lst.append(True)\n",
    "    else:\n",
    "        lst.append(False)\n",
    "print(len([i for i in lst if i == True])/len(lst)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正例に関する適合率 (precision rate)：　正例を正例と予測できた数 / 正例と予測した数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.75745307324254\n"
     ]
    }
   ],
   "source": [
    "lst = []\n",
    "for line in open('data/file76'):\n",
    "    x = line.split()\n",
    "    if x[0] == '1' and x[1] == '1':\n",
    "        lst.append(True)\n",
    "    elif x[1] == '1':\n",
    "        lst.append(False)\n",
    "print(len([i for i in lst if i == True])/len(lst)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再現率 (recall rate)：　正例を正例と予測できた数　/ 　実際の正例の数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.24048021009192\n"
     ]
    }
   ],
   "source": [
    "lst = []\n",
    "for line in open('data/file76'):\n",
    "    x = line.split()\n",
    "    if x[0] == '1' and x[1] == '1':\n",
    "        lst.append(True)\n",
    "    elif x[0] == '1':\n",
    "        lst.append(False)\n",
    "print(len([i for i in lst if i == True])/len(lst)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1スコア　適合率と再現率の調和平均 = ( 2 * 適合率　* 再現率 ) / ( 適合率 + 再現率 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.49187180678123\n"
     ]
    }
   ],
   "source": [
    "a=76.75745307324254\n",
    "b=78.24048021009192\n",
    "print((2 * a * b) / (a + b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 78. 5分割交差検定\n",
    "76-77の実験では，学習に用いた事例を評価にも用いたため，正当な評価とは言えない．すなわち，分類器が訓練事例を丸暗記する際の性能を評価しており，モデルの汎化性能を測定していない．そこで，5分割交差検定により，極性分類の正解率，適合率，再現率，F1スコアを求めよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
